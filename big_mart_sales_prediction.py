# -*- coding: utf-8 -*-
"""Big_mart_sales_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y4vvWCc5tKnyYJKvf5wR-3raCSzHl74y
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

from sklearn.metrics import mean_absolute_error as mae
from sklearn.metrics import r2_score , mean_squared_error
from math import sqrt

"""Collecting and Processing Data"""

#getting the data frame

bm_ds = pd.read_csv("/content/Train.csv")

# getting the firts five rows of the data frame 
bm_ds.head()

#No. of Data points
bm_ds.shape

#Stastical Information
bm_ds.describe()

# data type of attributes
bm_ds.info()

"""Categorical Features:-

*   Item_Identifier
*   Item_Fat_Content
*   Item_Type
*   Outlet_Identifier
*   Outlet_Size
*   Outlet_Location_Type
*   Outlet_Type


"""

# Checking missing values 
bm_ds.isnull().sum()

"""Handeling Missing Values"""

# mean value of "Item_Weight" column
bm_ds['Item_Weight'].mean()

# filling the missing values in "Item_weight column" with "Mean" value
bm_ds['Item_Weight'].fillna(bm_ds['Item_Weight'].mean(), inplace=True)

# mode of "Outlet_Size" column
bm_ds['Outlet_Size'].mode()

# filling the missing values in "Outlet_Size" column with Mode
mode_of_Outlet_size = bm_ds.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))

print(mode_of_Outlet_size)

miss_values = bm_ds['Outlet_Size'].isnull()

print(miss_values)

bm_ds.loc[miss_values, 'Outlet_Size'] = bm_ds.loc[miss_values,'Outlet_Type'].apply(lambda x: mode_of_Outlet_size[x])

# checking for missing values
bm_ds.isnull().sum()

"""Data Analysis"""

bm_ds.describe()

"""Numerical Features"""

sns.set()

# Item_Weight distribution
plt.figure(figsize=(6,6))
sns.distplot(bm_ds['Item_Weight'])
plt.show()

# Item Visibility distribution
plt.figure(figsize=(6,6))
sns.distplot(bm_ds['Item_Visibility'])
plt.show()

# Item MRP distribution
plt.figure(figsize=(6,6))
sns.distplot(bm_ds['Item_MRP'])
plt.show()

# Item_Outlet_Sales distribution
plt.figure(figsize=(6,6))
sns.distplot(bm_ds['Item_Outlet_Sales'])
plt.show()

# Outlet_Establishment_Year column
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Establishment_Year', data=bm_ds)
plt.show()

# Item_Fat_Content column
plt.figure(figsize=(6,6))
sns.countplot(x='Item_Fat_Content', data=bm_ds)
plt.show()

# Item_Type column
plt.figure(figsize=(30,6))
sns.countplot(x='Item_Type', data=bm_ds)
plt.show()

# Outlet_Size column
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Size', data=bm_ds)
plt.show()

# Outlet_Size column
plt.figure(figsize=(6,6))
sns.barplot(x='Outlet_Location_Type',y='Item_Outlet_Sales', data=bm_ds)
plt.show()

# Outlet_Size column
plt.figure(figsize=(6,6))
sns.barplot(x='Outlet_Identifier',y='Item_Outlet_Sales', data=bm_ds)
plt.show()

plt.figure(figsize=(8,8))
plt.scatter(bm_ds['Item_Visibility'],bm_ds['Item_Outlet_Sales'])
plt.xlabel('Item_Visibility')
plt.ylabel('Item_Outlet_Sales')
plt.show()

# Outlet_Size column
plt.figure(figsize=(6,6))
sns.barplot(x='Item_Type',y='Item_Outlet_Sales', data=bm_ds)
plt.show()

sns.heatmap(bm_ds.corr())

#fig,ax = plt.subplots(4,2,figsize=(15,15))
#sns.displot(bm_ds['Item_Visibility'],kde=True,ax=ax[0,0],color='green')
#sns.displot(bm_ds['Item_MRP'],kde=True, ax=ax[0,1],color='grey')
#sns.displot(bm_ds['Outlet_Identifier'],kde=True ,ax=ax[1,0],color='red')
#sns.displot(bm_ds['Outlet_Type'],kde=True, ax=ax[1,1],color='pink')
#sns.displot(bm_ds['Outlet_Size'],kde=True, ax=ax[2,0],color='blue')
#sns.displot(bm_ds['Outlet_Establishment_Year'],kde=True, ax=ax[3,0])
#sns.displot(bm_ds['Item_Outlet_Sales'],kde=True, ax=ax[3,1])

bm_ds.head()

bm_ds.skew()

bm_ds['Item_Fat_Content'].value_counts()

bm_ds.replace({'Item_Fat_Content': {'low fat':'Low Fat','LF':'Low Fat', 'reg':'Regular'}}, inplace=True)

bm_ds['Item_Fat_Content'].value_counts()

# Item_Fat_Content column
plt.figure(figsize=(6,6))
sns.countplot(x='Item_Fat_Content', data=bm_ds)
plt.show()

"""Label Encoding

"""

encoder = LabelEncoder()

bm_ds['Item_Identifier'] = encoder.fit_transform(bm_ds['Item_Identifier'])

bm_ds['Item_Fat_Content'] = encoder.fit_transform(bm_ds['Item_Fat_Content'])

bm_ds['Item_Type'] = encoder.fit_transform(bm_ds['Item_Type'])

bm_ds['Outlet_Identifier'] = encoder.fit_transform(bm_ds['Outlet_Identifier'])

bm_ds['Outlet_Size'] = encoder.fit_transform(bm_ds['Outlet_Size'])

bm_ds['Outlet_Location_Type'] = encoder.fit_transform(bm_ds['Outlet_Location_Type'])

bm_ds['Outlet_Type'] = encoder.fit_transform(bm_ds['Outlet_Type'])

bm_ds['Item_Outlet_Sales'] = encoder.fit_transform(bm_ds['Item_Outlet_Sales'])

bm_ds.head()

"""Spliting Feature and Targets"""

X = bm_ds.drop(columns='Item_Outlet_Sales', axis=1)
Y = bm_ds['Item_Outlet_Sales']

print(X)

print(Y)

"""Spliting Data as Training and Testing Data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Machine Learning Model Training

XGBoost Regressor
"""

regressor = XGBRegressor()

regressor.fit(X_train, Y_train)

# prediction on training data
X_pred = regressor.predict(X_train)

# R squared Value
r2_train = metrics.r2_score(Y_train, X_pred)

print('R Squared value = ', r2_train)

# prediction on test data
Y_pred = regressor.predict(X_test)

# R squared Value
r2_test = metrics.r2_score(Y_test, Y_pred)

print('R Squared value = ', r2_test)

predictions = [round(value) for value in Y_pred]
#predictions

rmse_1=sqrt(mean_squared_error(Y_test,Y_pred))
rmse_1

res_1 = Y_test - Y_pred

res_1

Y_test

plt.scatter(Y_test,res_1,color='black')
plt.xlabel('residual')
plt.ylabel('Y_test')
plt.axhline(y=0)

error_1=mae(Y_test,Y_pred)

print("Mean absolute error for XGBoost model : ",error_1)

"""## LINEAR REGRESSION"""

x = bm_ds.drop(columns='Item_Outlet_Sales', axis=1)
y = bm_ds['Item_Outlet_Sales']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)

from sklearn.linear_model import LinearRegression

regressor_1= LinearRegression()

regressor_1.fit(x_train,y_train)

y_prediction = regressor_1.predict(x_test)

r2_score(y_test,y_prediction)

rmse_2=sqrt(mean_squared_error(y_test,y_prediction))
rmse_2

res_2 = y_test - y_prediction

res_2

plt.scatter(y_test,res_2,color='red')
plt.xlabel('residual')
plt.ylabel('y_test')
plt.axhline(y=0)

error_2=mae(y_test,y_prediction)

print("Mean absolute error for linear regression model : ",error_2)

"""## KNN"""

from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

data=pd.read_csv('/content/Train.csv')
data

data.isnull().sum()

# mean value of "Item_Weight" column
data['Item_Weight'].mean()
# filling the missing values in "Item_weight column" with "Mean" value
data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)
# mode of "Outlet_Size" column
data['Outlet_Size'].mode()
# filling the missing values in "Outlet_Size" column with Mode
mode_of_Outlet_size = data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))
data.loc[miss_values, 'Outlet_Size'] = data.loc[miss_values,'Outlet_Type'].apply(lambda x: mode_of_Outlet_size[x])

data.isnull().sum()

data['Item_Fat_Content'].value_counts()

data.replace({'Item_Fat_Content': {'low fat':'Low Fat','LF':'Low Fat', 'reg':'Regular'}}, inplace=True)

data['Item_Fat_Content'].value_counts()

data['Outlet_Type'] = encoder.fit_transform(data['Outlet_Type'])
data['Outlet_Location_Type'] = encoder.fit_transform(data['Outlet_Location_Type'])
data['Outlet_Size'] = encoder.fit_transform(data['Outlet_Size'])
data['Outlet_Identifier'] = encoder.fit_transform(data['Outlet_Identifier'])
data['Item_Type'] = encoder.fit_transform(data['Item_Type'])
data['Item_Fat_Content'] = encoder.fit_transform(data['Item_Fat_Content'])
data['Item_Identifier'] = encoder.fit_transform(data['Item_Identifier'])
data['Item_Outlet_Sales'] = encoder.fit_transform(data['Item_Outlet_Sales'])

data

data.shape

x = data.drop(columns='Item_Outlet_Sales', axis=1)
y = data['Item_Outlet_Sales']

x.shape

y.shape

x_train , x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2)

#featrure scaling
sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)

#define the model : Init K-NN
classifier = KNeighborsClassifier(n_neighbors=11,p=2,metric='euclidean')

classifier.fit(x_train,y_train)

#predict the test set results
y_pred = classifier.predict(x_test)
y_pred

#evaluating our model
cm = confusion_matrix(y_test,y_pred)
print(cm)

print(accuracy_score(y_test,y_pred))

#print(f1_score(y_test , y_pred))